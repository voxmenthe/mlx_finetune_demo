{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Quantization with MLX-LM\n",
    "\n",
    "This notebook demonstrates how to use Dynamic Quantization with MLX-LM to estimate the sensitivity for each quantizable layer and apply different precision levels.\n",
    "\n",
    "## What is Dynamic Quantization?\n",
    "Dynamic quantization estimates the sensitivity for each quantizable layer and uses higher precision (e.g., 5 bits) for sensitive layers while using lower precision for less sensitive layers. This approach optimizes the balance between model size and quality.\n",
    "\n",
    "## Requirements\n",
    "- macOS with Apple Silicon (M1/M2/M3/M4)\n",
    "- Python 3.9+\n",
    "- MLX framework\n",
    "- Sufficient disk space for model storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Environment setup\n",
    "print(\"Setting up environment for Dynamic quantization...\")\n",
    "\n",
    "# Create project directories\n",
    "project_dir = Path.cwd()\n",
    "models_dir = project_dir / \"models\"\n",
    "sensitivity_dir = project_dir / \"sensitivities\"  # For storing sensitivity files\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "sensitivity_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project directory: {project_dir}\")\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "print(f\"Sensitivity directory: {sensitivity_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install MLX and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing MLX and dependencies...\")\n",
    "\n",
    "packages = [\n",
    "    \"mlx-lm\",\n",
    "    \"transformers\",\n",
    "    \"torch\", \n",
    "    \"huggingface_hub\",\n",
    "    \"datasets\",\n",
    "    \"accelerate\",\n",
    "    \"sentencepiece\",\n",
    "    \"protobuf\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                      check=True, capture_output=True, text=True)\n",
    "        print(f\"‚úÖ {package} installed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ö†Ô∏è Warning installing {package}: {e}\")\n",
    "\n",
    "print(\"\\nüì¶ All packages installation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test MLX Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "print(\"Testing MLX imports...\")\n",
    "\n",
    "try:\n",
    "    import mlx.core as mx\n",
    "    from mlx_lm import load, generate\n",
    "    from huggingface_hub import login, snapshot_download\n",
    "    print(\"‚úÖ All imports successful!\")\n",
    "    \n",
    "    # Test MLX functionality\n",
    "    test_array = mx.array([1, 2, 3])\n",
    "    print(f\"‚úÖ MLX test array: {test_array}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import failed: {e}\")\n",
    "    print(\"Please restart kernel and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Quantization Configuration\n",
    "print(\"=== Dynamic Quantization Configuration ===\\n\")\n",
    "\n",
    "# Model to quantize (you can change this)\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"  # Small model for demonstration\n",
    "\n",
    "# Dynamic Quantization Parameters\n",
    "DYNAMIC_CONFIG = {\n",
    "    \"target_bpw\": 4.0,               # Target bits-per-weight\n",
    "    \"low_bits\": 2,                   # Precision for less sensitive layers\n",
    "    \"high_bits\": 8,                  # Precision for sensitive layers\n",
    "    \"num_samples\": 512,              # Samples for sensitivity analysis\n",
    "    \"group_size\": 128,               # Group size for quantization\n",
    "}\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Target bits-per-weight: {DYNAMIC_CONFIG['target_bpw']}\")\n",
    "print(f\"Low precision: {DYNAMIC_CONFIG['low_bits']} bits\")\n",
    "print(f\"High precision: {DYNAMIC_CONFIG['high_bits']} bits\")\n",
    "print(f\"Sensitivity samples: {DYNAMIC_CONFIG['num_samples']}\")\n",
    "print(f\"Group size: {DYNAMIC_CONFIG['group_size']}\")\n",
    "\n",
    "# Set up directories\n",
    "model_safe_name = MODEL_NAME.replace(\"/\", \"_\")\n",
    "original_model_dir = models_dir / model_safe_name\n",
    "dynamic_model_dir = models_dir / f\"{model_safe_name}_Dynamic_{DYNAMIC_CONFIG['target_bpw']}bpw\"\n",
    "sensitivity_file = sensitivity_dir / f\"{model_safe_name}_sensitivity.json\"\n",
    "\n",
    "print(f\"\\nOriginal model dir: {original_model_dir}\")\n",
    "print(f\"Dynamic model dir: {dynamic_model_dir}\")\n",
    "print(f\"Sensitivity file: {sensitivity_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(f\"Downloading {MODEL_NAME}...\")\n",
    "print(\"This may take a while depending on model size and internet connection.\")\n",
    "\n",
    "# Create directories\n",
    "original_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check if model already exists\n",
    "if list(original_model_dir.glob(\"*\")):\n",
    "    print(f\"Model files found in {original_model_dir}\")\n",
    "    use_existing = input(\"Use existing model files? (y/n): \").strip().lower()\n",
    "    if use_existing != 'y':\n",
    "        import shutil\n",
    "        shutil.rmtree(original_model_dir)\n",
    "        original_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not list(original_model_dir.glob(\"*\")):\n",
    "    try:\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        downloaded_path = snapshot_download(\n",
    "            repo_id=MODEL_NAME,\n",
    "            local_dir=str(original_model_dir),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        print(f\"‚úÖ Model downloaded successfully in {duration}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download failed: {e}\")\n",
    "        print(\"Please check the model name and internet connection.\")\n",
    "\n",
    "# List downloaded files\n",
    "print(\"\\nModel files:\")\n",
    "total_size = 0\n",
    "for file in original_model_dir.glob(\"*\"):\n",
    "    if file.is_file():\n",
    "        size_mb = file.stat().st_size / 1024 / 1024\n",
    "        total_size += size_mb\n",
    "        print(f\"  {file.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(f\"\\nTotal model size: {total_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Sensitivity Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Check if we already have a sensitivity file\n",
    "print(\"=== Layer Sensitivity Analysis ===\\n\")\n",
    "\n",
    "if sensitivity_file.exists():\n",
    "    print(f\"Sensitivity file found: {sensitivity_file}\")\n",
    "    use_existing = input(\"Use existing sensitivity analysis? (y/n): \").strip().lower()\n",
    "    \n",
    "    if use_existing == 'y':\n",
    "        # Load existing sensitivity data\n",
    "        with open(sensitivity_file, 'r') as f:\n",
    "            sensitivity_data = json.load(f)\n",
    "        print(f\"‚úÖ Loaded existing sensitivity data with {len(sensitivity_data)} layers\")\n",
    "    else:\n",
    "        # Run new sensitivity analysis\n",
    "        print(\"Running new sensitivity analysis...\")\n",
    "        run_sensitivity = True\nelse:\n",
    "    print(\"No existing sensitivity file found.\")\n",
    "    run_analysis = input(\"Run sensitivity analysis first? (recommended, y/n): \").strip().lower()\n",
    "    run_sensitivity = run_analysis == 'y'\n",
    "\n",
    "if run_sensitivity:\n",
    "    print(\"\\nüîÑ Running sensitivity analysis...\")\n",
    "    print(\"This will analyze which layers are most sensitive to quantization.\")\n",
    "    print(\"This may take some time...\")\n",
    "    \n",
    "    # Note: MLX-LM might not have a separate sensitivity analysis command\n",
    "    # This is a conceptual step - the actual dynamic quantization will\n",
    "    # perform this analysis internally\n",
    "    \n",
    "    try:\n",
    "        # Create a dummy sensitivity analysis (as MLX-LM handles this internally)\n",
    "        print(\"Dynamic quantization will perform sensitivity analysis internally...\")\n",
    "        \n",
    "        # Create a placeholder sensitivity file for demonstration\n",
    "        sample_sensitivity = {\n",
    "            \"analysis_date\": datetime.now().isoformat(),\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"samples_used\": DYNAMIC_CONFIG['num_samples'],\n",
    "            \"note\": \"Sensitivity analysis performed internally by mlx_lm.dynamic_quant\"\n",
    "        }\n",
    "        \n",
    "        with open(sensitivity_file, 'w') as f:\n",
    "            json.dump(sample_sensitivity, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Sensitivity analysis placeholder created: {sensitivity_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in sensitivity analysis: {e}\")\nelse:\n",
    "    print(\"Skipping sensitivity analysis - will use dynamic quantization defaults.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Starting Dynamic quantization...\")\n",
    "print(f\"Source: {original_model_dir}\")\n",
    "print(f\"Target: {dynamic_model_dir}\")\n",
    "print(f\"Configuration: {DYNAMIC_CONFIG}\")\n",
    "\n",
    "# Clean up existing dynamic directory\n",
    "if dynamic_model_dir.exists():\n",
    "    print(f\"Removing existing dynamic directory: {dynamic_model_dir}\")\n",
    "    shutil.rmtree(dynamic_model_dir)\n",
    "\n",
    "dynamic_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Build Dynamic quantization command\n",
    "dynamic_cmd = [\n",
    "    \"python\", \"-m\", \"mlx_lm.dynamic_quant\",\n",
    "    \"--model\", str(original_model_dir),\n",
    "    \"--mlx-path\", str(dynamic_model_dir),\n",
    "    \"--target-bpw\", str(DYNAMIC_CONFIG[\"target_bpw\"]),\n",
    "    \"--low-bits\", str(DYNAMIC_CONFIG[\"low_bits\"]),\n",
    "    \"--high-bits\", str(DYNAMIC_CONFIG[\"high_bits\"])\n",
    "]\n",
    "\n",
    "# Add sensitivity file if it exists and contains actual data\n",
    "if sensitivity_file.exists():\n",
    "    # Check if it's a real sensitivity file (not our placeholder)\n",
    "    with open(sensitivity_file, 'r') as f:\n",
    "        sens_data = json.load(f)\n",
    "    \n",
    "    if \"note\" not in sens_data:  # Real sensitivity data\n",
    "        dynamic_cmd.extend([\"--sensitivities\", str(sensitivity_file)])\n",
    "        print(f\"Using sensitivity file: {sensitivity_file}\")\n",
    "\n",
    "print(f\"\\nRunning command: {' '.join(dynamic_cmd)}\")\n",
    "\n",
    "try:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Run Dynamic quantization\n",
    "    result = subprocess.run(\n",
    "        dynamic_cmd,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=str(project_dir)\n",
    "    )\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"\\n‚úÖ Dynamic quantization completed successfully in {duration}!\")\n",
    "        print(\"STDOUT:\", result.stdout)\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Dynamic quantization failed!\")\n",
    "        print(\"STDERR:\", result.stderr)\n",
    "        print(\"STDOUT:\", result.stdout)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running Dynamic quantization: {e}\")\n",
    "\n",
    "# Check results\n",
    "if dynamic_model_dir.exists() and list(dynamic_model_dir.glob(\"*\")):\n",
    "    print(\"\\nDynamic quantized files:\")\n",
    "    total_dynamic_size = 0\n",
    "    for file in dynamic_model_dir.glob(\"*\"):\n",
    "        if file.is_file():\n",
    "            size_mb = file.stat().st_size / 1024 / 1024\n",
    "            total_dynamic_size += size_mb\n",
    "            print(f\"  {file.name} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    print(f\"\\nTotal dynamic model size: {total_dynamic_size:.2f} MB\")\n",
    "    if total_size > 0:\n",
    "        print(f\"Size reduction: {((total_size - total_dynamic_size) / total_size * 100):.1f}%\")\n",
    "        print(f\"Actual bits-per-weight: {(total_dynamic_size / total_size * 16):.2f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Quantization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the quantization results\n",
    "if dynamic_model_dir.exists() and list(dynamic_model_dir.glob(\"*\")):\n",
    "    print(\"=== Dynamic Quantization Analysis ===\")\n",
    "    \n",
    "    # Check for quantization info files\n",
    "    quant_info_files = list(dynamic_model_dir.glob(\"*.json\"))\n",
    "    \n",
    "    for info_file in quant_info_files:\n",
    "        if \"quant\" in info_file.name.lower() or \"config\" in info_file.name.lower():\n",
    "            print(f\"\\nüìä Quantization info from {info_file.name}:\")\n",
    "            try:\n",
    "                with open(info_file, 'r') as f:\n",
    "                    info_data = json.load(f)\n",
    "                \n",
    "                # Display relevant quantization information\n",
    "                for key, value in info_data.items():\n",
    "                    if any(word in key.lower() for word in ['quant', 'bit', 'precision', 'group']):\n",
    "                        print(f\"   {key}: {value}\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"   Could not read {info_file.name}: {e}\")\n",
    "    \n",
    "    # Model size comparison\n",
    "    print(f\"\\nüìè Size Comparison:\")\n",
    "    print(f\"   Original: {total_size:.2f} MB\")\n",
    "    print(f\"   Dynamic:  {total_dynamic_size:.2f} MB\")\n",
    "    print(f\"   Reduction: {((total_size - total_dynamic_size) / total_size * 100):.1f}%\")\n",
    "    \n",
    "    # Estimate compression ratio\n",
    "    compression_ratio = total_size / total_dynamic_size if total_dynamic_size > 0 else 0\n",
    "    print(f\"   Compression ratio: {compression_ratio:.2f}x\")\nelse:\n",
    "    print(\"‚ùå Dynamic model not found. Quantization may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test Dynamic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Dynamic quantized model\n",
    "if dynamic_model_dir.exists() and list(dynamic_model_dir.glob(\"*\")):\n",
    "    print(\"Testing Dynamic quantized model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load the Dynamic model\n",
    "        model, tokenizer = load(str(dynamic_model_dir))\n",
    "        print(\"‚úÖ Dynamic model loaded successfully!\")\n",
    "        \n",
    "        # Test generation with various prompts\n",
    "        test_prompts = [\n",
    "            \"Hello, how are you today?\",\n",
    "            \"The weather forecast shows\",\n",
    "            \"Artificial intelligence technology\",\n",
    "            \"In the field of machine learning\",\n",
    "            \"Dynamic quantization helps\"\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n=== Dynamic Model Test Results ===\")\n",
    "        for i, prompt in enumerate(test_prompts, 1):\n",
    "            print(f\"\\n[Test {i}] Prompt: '{prompt}'\")\n",
    "            \n",
    "            response = generate(\n",
    "                model, \n",
    "                tokenizer, \n",
    "                prompt=prompt, \n",
    "                max_tokens=60,\n",
    "                temp=0.7\n",
    "            )\n",
    "            \n",
    "            print(f\"Response: {response}\")\n",
    "            \n",
    "        print(\"\\n‚úÖ Dynamic model is working correctly!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing Dynamic model: {e}\")\nelse:\n",
    "    print(\"‚ùå Dynamic model not found. Quantization may have failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Compare original vs Dynamic model performance\n",
    "import time\n",
    "\n",
    "compare_models = input(\"Do you want to compare original vs Dynamic model performance? (y/n): \").strip().lower()\n",
    "\n",
    "if compare_models == 'y':\n",
    "    print(\"\\n=== Performance Comparison ===\")\n",
    "    \n",
    "    test_prompt = \"Dynamic quantization is a technique that\"\n",
    "    max_tokens = 80\n",
    "    num_runs = 3  # Multiple runs for average timing\n",
    "    \n",
    "    try:\n",
    "        # Test original model\n",
    "        print(\"\\nüîÑ Testing original model...\")\n",
    "        original_model, original_tokenizer = load(str(original_model_dir))\n",
    "        \n",
    "        original_times = []\n",
    "        for run in range(num_runs):\n",
    "            start_time = time.time()\n",
    "            original_response = generate(\n",
    "                original_model, \n",
    "                original_tokenizer, \n",
    "                prompt=test_prompt, \n",
    "                max_tokens=max_tokens,\n",
    "                temp=0.7\n",
    "            )\n",
    "            original_times.append(time.time() - start_time)\n",
    "        \n",
    "        avg_original_time = sum(original_times) / len(original_times)\n",
    "        print(f\"Original response: {original_response}\")\n",
    "        print(f\"Original avg time: {avg_original_time:.2f}s (over {num_runs} runs)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing original model: {e}\")\n",
    "        avg_original_time = None\n",
    "    \n",
    "    try:\n",
    "        # Test Dynamic model (already loaded above)\n",
    "        print(\"\\nüîÑ Testing Dynamic model...\")\n",
    "        \n",
    "        dynamic_times = []\n",
    "        for run in range(num_runs):\n",
    "            start_time = time.time()\n",
    "            dynamic_response = generate(\n",
    "                model, \n",
    "                tokenizer, \n",
    "                prompt=test_prompt, \n",
    "                max_tokens=max_tokens,\n",
    "                temp=0.7\n",
    "            )\n",
    "            dynamic_times.append(time.time() - start_time)\n",
    "        \n",
    "        avg_dynamic_time = sum(dynamic_times) / len(dynamic_times)\n",
    "        print(f\"Dynamic response: {dynamic_response}\")\n",
    "        print(f\"Dynamic avg time: {avg_dynamic_time:.2f}s (over {num_runs} runs)\")\n",
    "        \n",
    "        # Compare performance\n",
    "        if avg_original_time and avg_dynamic_time:\n",
    "            speedup = avg_original_time / avg_dynamic_time\n",
    "            print(f\"\\nüìä Performance Summary:\")\n",
    "            print(f\"   Speedup: {speedup:.2f}x\")\n",
    "            print(f\"   Time saved per generation: {avg_original_time - avg_dynamic_time:.2f}s\")\n",
    "            print(f\"   Model size reduction: {((total_size - total_dynamic_size) / total_size * 100):.1f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing Dynamic model: {e}\")\nelse:\n",
    "    print(\"Skipping performance comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Evaluate Model Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Evaluate the quantized model\n",
    "print(\"=== Model Quality Evaluation ===\\n\")\n",
    "\n",
    "evaluate_model = input(\"Do you want to evaluate model quality? (y/n): \").strip().lower()\n",
    "\n",
    "if evaluate_model == 'y':\n",
    "    # You can use mlx_lm.evaluate for this\n",
    "    eval_cmd = [\n",
    "        \"python\", \"-m\", \"mlx_lm.evaluate\",\n",
    "        \"--model\", str(dynamic_model_dir),\n",
    "        \"--dataset\", \"wikitext\",  # or your preferred dataset\n",
    "        \"--few-shot\", \"5\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running evaluation: {' '.join(eval_cmd)}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(eval_cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n‚úÖ Evaluation completed!\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"\\n‚ùå Evaluation failed!\")\n",
    "            print(result.stderr)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error running evaluation: {e}\")\nelse:\n",
    "    print(\"Skipping evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Upload to Hugging Face (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, upload_folder\n",
    "import getpass\n",
    "\n",
    "upload_to_hf = input(\"Do you want to upload the Dynamic model to Hugging Face? (y/n): \").strip().lower()\n",
    "\n",
    "if upload_to_hf == 'y':\n",
    "    # Get Hugging Face credentials\n",
    "    print(\"Please enter your Hugging Face token:\")\n",
    "    hf_token = getpass.getpass(\"HF Token: \")\n",
    "    \n",
    "    try:\n",
    "        login(token=hf_token)\n",
    "        print(\"‚úÖ Successfully logged in to Hugging Face!\")\n",
    "        \n",
    "        # Get repository name\n",
    "        repo_name = input(\"Enter repository name (e.g., 'username/model-name-dynamic'): \").strip()\n",
    "        \n",
    "        # Create repository\n",
    "        api = HfApi()\n",
    "        api.create_repo(repo_id=repo_name, repo_type=\"model\", exist_ok=True)\n",
    "        print(f\"‚úÖ Repository {repo_name} created!\")\n",
    "        \n",
    "        # Create model card\n",
    "        model_card = f\"\"\"---\n",
    "license: apache-2.0\n",
    "base_model: {MODEL_NAME}\n",
    "tags:\n",
    "- mlx\n",
    "- dynamic-quantization\n",
    "- quantized\n",
    "- mixed-precision\n",
    "---\n",
    "\n",
    "# {MODEL_NAME.split('/')[-1]} - Dynamic Quantization {DYNAMIC_CONFIG['target_bpw']}bpw\n",
    "\n",
    "This is a Dynamic Quantization version of [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME}) with {DYNAMIC_CONFIG['target_bpw']} target bits-per-weight.\n",
    "\n",
    "## Quantization Details\n",
    "- Method: Dynamic Quantization (Mixed Precision)\n",
    "- Target bits-per-weight: {DYNAMIC_CONFIG['target_bpw']}\n",
    "- Low precision: {DYNAMIC_CONFIG['low_bits']} bits (less sensitive layers)\n",
    "- High precision: {DYNAMIC_CONFIG['high_bits']} bits (sensitive layers)\n",
    "- Group size: {DYNAMIC_CONFIG['group_size']}\n",
    "\n",
    "## Features\n",
    "- Automatically estimates layer sensitivity\n",
    "- Uses different precision for different layers\n",
    "- Optimized balance between size and quality\n",
    "- Optimized for Apple Silicon devices\n",
    "\n",
    "## How Dynamic Quantization Works\n",
    "Dynamic quantization analyzes the sensitivity of each layer to quantization and applies:\n",
    "- Higher precision ({DYNAMIC_CONFIG['high_bits']} bits) for sensitive layers\n",
    "- Lower precision ({DYNAMIC_CONFIG['low_bits']} bits) for less sensitive layers\n",
    "\n",
    "This approach maintains model quality while achieving significant size reduction.\n",
    "\n",
    "## Usage\n",
    "```python\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "model, tokenizer = load(\"{repo_name}\")\n",
    "response = generate(model, tokenizer, prompt=\"Hello\", max_tokens=100)\n",
    "```\n",
    "\"\"\"\n",
    "        \n",
    "        # Save model card\n",
    "        with open(dynamic_model_dir / \"README.md\", \"w\") as f:\n",
    "            f.write(model_card)\n",
    "        \n",
    "        # Upload\n",
    "        print(f\"Uploading to {repo_name}...\")\n",
    "        upload_folder(\n",
    "            folder_path=str(dynamic_model_dir),\n",
    "            repo_id=repo_name,\n",
    "            repo_type=\"model\",\n",
    "            commit_message=f\"Add Dynamic quantized model ({DYNAMIC_CONFIG['target_bpw']}bpw)\"\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Model uploaded successfully!\")\n",
    "        print(f\"üîó https://huggingface.co/{repo_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Upload failed: {e}\")\nelse:\n",
    "    print(\"Skipping upload.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ DYNAMIC QUANTIZATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìã Configuration:\")\n",
    "print(f\"   Base Model: {MODEL_NAME}\")\n",
    "print(f\"   Target BPW: {DYNAMIC_CONFIG['target_bpw']}\")\n",
    "print(f\"   Low Precision: {DYNAMIC_CONFIG['low_bits']} bits\")\n",
    "print(f\"   High Precision: {DYNAMIC_CONFIG['high_bits']} bits\")\n",
    "print(f\"   Group Size: {DYNAMIC_CONFIG['group_size']}\")\n",
    "\n",
    "print(f\"\\nüìÅ Directories:\")\n",
    "print(f\"   Original: {original_model_dir}\")\n",
    "print(f\"   Dynamic Model: {dynamic_model_dir}\")\n",
    "print(f\"   Sensitivity File: {sensitivity_file}\")\n",
    "\n",
    "# Check if quantization was successful\n",
    "if dynamic_model_dir.exists() and list(dynamic_model_dir.glob(\"*\")):\n",
    "    print(f\"\\n‚úÖ Status: Dynamic quantization completed successfully!\")\n",
    "    \n",
    "    # Calculate metrics if available\n",
    "    if 'total_size' in locals() and 'total_dynamic_size' in locals():\n",
    "        size_reduction = ((total_size - total_dynamic_size) / total_size * 100)\n",
    "        compression_ratio = total_size / total_dynamic_size\n",
    "        actual_bpw = (total_dynamic_size / total_size * 16)\n",
    "        \n",
    "        print(f\"   Original size: {total_size:.2f} MB\")\n",
    "        print(f\"   Dynamic size: {total_dynamic_size:.2f} MB\")\n",
    "        print(f\"   Size reduction: {size_reduction:.1f}%\")\n",
    "        print(f\"   Compression ratio: {compression_ratio:.2f}x\")\n",
    "        print(f\"   Actual bits-per-weight: {actual_bpw:.2f}\")\nelse:\n",
    "    print(f\"\\n‚ùå Status: Dynamic quantization failed or incomplete\")\n",
    "\n",
    "print(f\"\\nüí° Dynamic Quantization Advantages:\")\n",
    "print(f\"   ‚Ä¢ Adaptive precision based on layer sensitivity\")\n",
    "print(f\"   ‚Ä¢ Better quality preservation than uniform quantization\")\n",
    "print(f\"   ‚Ä¢ Automatic sensitivity analysis\")\n",
    "print(f\"   ‚Ä¢ Optimal balance between size and performance\")\n",
    "\n",
    "print(f\"\\nüîß Tuning Tips:\")\n",
    "print(f\"   ‚Ä¢ Lower target-bpw = smaller model, potentially lower quality\")\n",
    "print(f\"   ‚Ä¢ Adjust high-bits/low-bits spread for different trade-offs\")\n",
    "print(f\"   ‚Ä¢ Use sensitivity analysis for fine-tuning\")\n",
    "print(f\"   ‚Ä¢ Test with your specific use case to validate quality\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Thank you for using Dynamic quantization!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}