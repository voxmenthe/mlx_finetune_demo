# mlx_lm.evaluate --model Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr1e-6 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

# echo "Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr2e7"
# mlx_lm.evaluate --model Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr2e7 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr4e7"
mlx_lm.evaluate --model Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr4e7 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr5e-8"
mlx_lm.evaluate --model Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr5e-8 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr9e8"
mlx_lm.evaluate --model Qwen3-Coder-30B-A3B-Instruct-8bit-DWQ-lr9e8 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr1e-7"
mlx_lm.evaluate --model Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr1e-7 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr2e-7"
mlx_lm.evaluate --model Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr2e-7 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr3e-8"
mlx_lm.evaluate --model Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr3e-8 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-30B-A3B-Instruct-2507-bit-DWQ-lr5e-7"
mlx_lm.evaluate --model Qwen3-30B-A3B-Instruct-2507-bit-DWQ-lr5e-7 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template

echo "Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr9e-8"
mlx_lm.evaluate --model Qwen3-30B-A3B-Instruct-2507-5bit-DWQ-lr9e-8 --tasks mmlu_pro_computer_science --max-tokens 5000 --no-apply-chat-template
